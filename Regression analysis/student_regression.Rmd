---
title: "Regression modelling"
author: "Kryštof Tomsa"
date: "2024-10-06"
output: html_document
---

This project aims to analyze student performance in math exam. The data was downloaded from Kaggle:
https://www.kaggle.com/datasets/spscientist/students-performance-in-exams

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, message = F, warning = F)
```

```{r}
# Load data and model
library(tidyverse)
library(car)
library(lmtest)
library(stargazer)
library(sandwich)

# https://www.kaggle.com/datasets/spscientist/students-performance-in-exams
data <- read.csv("C:/Users/kryst/OneDrive/Documents/Škola/Vysoká/Projects/Regression/StudentsPerformance.csv")
```


# Exploratory Data Analysis
Our dataset has 1000 observations and 8 variables (including our dependent variable). We can inspect our data below:

```{r}
summary(data)
```

We have 3 continuous variables (again including the dependent variable) and 5 nominal variables. Let's now look at the variables in more detail. 

```{r}
data %>%
  ggplot(mapping = aes(x=math.score)) + geom_histogram() + xlab("math score") + 
  ggtitle("Histogram of math scores") + theme(plot.title = element_text(hjust = 0.5))
```

The independent variable (math score) looks more or less normally distributed, but there are some outliers. For now, we will leave them in our data.

```{r}
data %>%
  ggplot(mapping = aes(x=gender, y=math.score)) + geom_boxplot() + 
  ylab("math score") + ggtitle("Boxplots of math scores by gender") + 
  theme(plot.title = element_text(hjust = 0.5))
```

This graphs showd us boxplots of math score for both females and males. Although, the males seem to perform better on average, the difference is not that big.

```{r}
data %>%
  ggplot(mapping = aes(x=race.ethnicity, y=math.score)) + geom_boxplot() + 
  xlab("race/ethnicity") + ylab("math score") + ggtitle("Boxplots of math scores by race/ethnicity") +
  theme(plot.title = element_text(hjust = 0.5))
```

Now have have a graph of boxplots for every race/ethnicity. In this case there definitely are differences, for example the difference in medians between group A and E is about 15 points.

```{r}
data %>%
  ggplot(mapping = aes(x=parental.level.of.education, y=math.score)) + geom_boxplot() + 
  xlab("parental level of education") + ylab("math score") + 
  ggtitle("Boxplots of math scores by parental level of education") + 
  theme(plot.title = element_text(hjust = 0.5))
```

This graph shows the distribution of math scores for different levels of parental education. Again we can observe differences in medians, but this time there are also some differences in ditributions.

```{r}
data %>%
  ggplot(mapping = aes(x=lunch, y=math.score)) + geom_boxplot() +
  xlab("lunch price") + ylab("math score") + 
  ggtitle("Boxplots of math scores by lunch price") + theme(plot.title = element_text(hjust = 0.5))
```

This graph is focused on lunch prices. The student (or parents) can either buy the lunch for a full price, have the price reduced or have the lunch entirely for free. This will probably have a correlation with the family's income.

```{r}
data %>%
  ggplot(mapping = aes(x=test.preparation.course, y=math.score)) + geom_boxplot() +
  xlab("preparation course") + ylab("math score") + 
  ggtitle("Boxplots of math scores by preparation course indicator") + 
  theme(plot.title = element_text(hjust = 0.5))
```

The last nominal attribute we will look at is whether the student finished the test preparation course. Unsurprisingly the median score for the students that finished the course is higher.

Now we will inspect the correlation between the math and reading score:

```{r}
data %>%
  ggplot(mapping = aes(x=reading.score, y=math.score)) + geom_point() +
  xlab("reading score") + ylab("math score") + 
  ggtitle("Correlation between reading and math score") + 
  theme(plot.title = element_text(hjust = 0.5))
```

The correlation is pretty high. What about the math score versus writing score?

```{r}
data %>%
  ggplot(mapping = aes(x=writing.score, y=math.score)) + geom_point() +
  xlab("writing score") + ylab("math score") + 
  ggtitle("Correlation between writing and math score") + 
  theme(plot.title = element_text(hjust = 0.5))
```

Again very high correlation. That could mean, that writing and reading scores are also correlated.

```{r}
read_write_cor <- cor(data$writing.score, data$reading.score)

data %>%
  ggplot(mapping = aes(x=writing.score, y=reading.score)) + geom_point() +
  xlab("writing score") + ylab("reading score") + 
  ggtitle("Correlation between writing and reading score") + 
  theme(plot.title = element_text(hjust = 0.5))
```

And they are! The correlation is `r round(read_write_cor,3)`. However, this means, that we have a problem, because high correlation could cause our estimates to have a high variance and therefore not be reliable. We can fix this by creating a new attribute that will combine the information from the two attributes and we will use in our model instead of them. In this case, we decided this feature will be the mean of the scores.

```{r}
data <- data %>%
  rowwise() %>%
  mutate("read.write.mean" = mean(c(reading.score, writing.score)))
```

# Modelling - 1
We will estimate our model as:
$$math.score = \beta_{0} + \beta_{1}*gender + \beta_{2}*race.ethnicity + \beta_{3}*parental.level.of.education + \beta_{4}*lunch + $$
$$\beta_{5}*test.preparation.course + \beta_{6}*read.write.mean + \beta_{7}*gender*read.write.mean + u$$
```{r}
model <- lm(math.score ~ gender + race.ethnicity + parental.level.of.education + 
              lunch  + test.preparation.course + read.write.mean + 
              gender:read.write.mean, data=data)
options(width = 500)
summary(model)
```

Now that we have our model, let's interpret the results above. First, look at the $adjusted R^2$. We can see, that our model explained `r round(summary(model)$adj.r.squared,3)*100`% of total variance in our data. That's pretty good.

Now we can interpret the individual coefficients (estimates). For example the coefficient for test preparation course variable tell us, that other variables being held equal the students without the course score on average `r round(coef(model)[13],2)` more points than those with the course. This is an interesting finding, because the boxplots in previous sections told us that the math score is higher for students with the course.

We also included interaction term in our model. This has different interpretation than other coefficients. In the term we included our gender variable and variable of mean of writing and reading scores, this basically means that we expect that genders have different effect on the mean of writing and reading scores. If we want to get the math score for women we just use the $\beta_{13}$ coefficient, for men we however need to use $\beta_{1} + (\beta_{13} + \beta_{14}) * read.write.mean$.

Before we move forward though, we should check for some assumptions, that make our model possible. Let's try to look at the issue of correlation between the independent variables, also called multicollinearity. Although we probably dealt with this problem by creating the new variable, it is still better to check.

```{r}
vif(model)
```

These are the variance inflation factors. The problem is, that there is no high or low value (sometimes we can find in articles that value 10 or 5 is high enough to conclude we have a problem with multicollinearity, but there is no scientific proof for that). Nevertheless, the values are pretty low and the high value between the gender and interaction term is expected and should not cause any problem.

Now we can look at the problem of heteroskedasticity. This is important for hypothesis testing.

```{r}
ggplot(mapping=aes(x=model$fitted.values, y=model$residuals)) + geom_point() + 
  xlab("fitted values") + ylab("residuals") + ggtitle("Fitted values vs residuals") +
  theme(plot.title = element_text(hjust = 0.5))
```

```{r}
bptest(model)
```

From the graph it seems that the errors are homoskedastic. We can also use Breusch-Pagan (or White) test to test for homoskedasticity. This test has following null and alternative hypothesis:
$$H_{0} = homoskedasticity$$
$$H_{1} = heteroskedasticity$$
From the p-value we cannot reject the null hypothesis. However, the p-value is pretty small, so we will behave as we have the heteroskedasticity in our model nevertheless. We deal with this by adjusting the variance of our coefficients.

```{r}
vcm <- vcovHC(model, "HC1")
S(model, vcov. = vcm)
```

This is our new model summary with the adjusted with variances. Now we can test the hypotheses. Reader can read the p-values from the above table and the stars on the right (1 or more stars means we reject the null hypothesis on 95% significance level, meaning the variable is statistically significant). We might be also interested in testing the joint significance using F-tests for our nominal variables.

```{r}
linearHypothesis(model, grep("race\\.ethnicity.*", names(coef(model)), value = T), vcov. = vcm)
```

We see that the race/ethnicity is significant. Let's try test for parental level of education.

```{r}
linearHypothesis(model, grep("parental\\.level.*", names(coef(model)), value = T), vcov. = vcm)
```

Again we can conclude, that the variable is statistically significant.

Lastly, instead of point estimates we might want to present confidence interval. Confidence intervals  offer more information than tests (which we can still do with confidence intervals).

```{r}
Confint(model, .vcov = vcm)
```

# Modelling - 2
In articles it is more common to use percentages for quantifying the effect rather than original values.
We can do this by logarithmic transformation of the dependent variable. For this model we will get rid of outliers and present the model's summary with adjusted variances.

```{r}
upper_border <- quantile(data$math.score, 0.75) + 1.5*IQR(data$math.score)
lower_border <- quantile(data$math.score, 0.25) - 1.5*IQR(data$math.score)

data_cleaned <- data[data$math.score < upper_border & data$math.score > lower_border,]

model_2 <- lm(log(math.score) ~ gender + race.ethnicity + parental.level.of.education + 
                lunch  + test.preparation.course + log(read.write.mean), data=data_cleaned)

vcm_2 <- vcovHC(model_2, "HC1")

S(model_2, vcov. = vcm_2)
```

Now if we want to get the effect of a variable on math score quantified in percentages we need to calculate $[exp(\beta_{j})-1]*100$. Also, in this model we did not include the interactions term, but we transformed the mean of writing and reading scores to have logarithmic scale. This coefficient is directly interpreted as $1\%$ change in the mean of the reading and writing scores is $x\%$ change in math score.

It is worth noting that the more transformations we use, the harder it is to interpret the results.

# Conclussion
The model shows us how different variable have different effects on student's performance in math test. All of our attributes were statistically significant. From the coefficients we can see that gender has a huge difference on the student's performance together with race/ethnicity group E. Lunch price and test preparation course had a medium effect on the performance. The mean of the writing and reading scores had a big effect on math score, meaning if student is good at writing and reading, he is also good at math. Although the parental level of education was statistically significant, the effect on performance was very small. 

We can (or actually we should) of course question the causal relations between the dependent and independent variables. For example, the mean of reading and writing score in this case kind of measure the student's intelligence and consistence in learning. The lunch price is definitely based on some economic well-being of the student's family and there are economic factors that could also influence our race/ethnicity variable. Also it would be interesting to find why males have high score in math than women. This of course does not immediately that females are worse in math. For example, it could be caused by different interests between genders. However, any of these factors were not present in our dataset, so we can only speculate. 